* DONE Get linear_regression.py to live-plot values of interest
** Average training, testing costs
* DONE Write unit test for ReLU node.
* DONE Write unit test for Softmax node, against pylearn2's.
* Implement CrossEntropy node, unit-test against pylearn2's.
* Implement Dropout
* Check out Fuel as a source of dataset wrappers
** https://github.com/bartvm/fuel
** If unsatisfactory, Implement data.Mnist, test against pylearn2.datasets.Mnist
*** Searches for cached mnist memmaps, creates them if necessary.
* Write examples/mnist_fully_connected.py
** Stack AffineTransform, Softmax, and CrossEntropy into a fully-connected NN, with layer geometries chosen from pylearn2's tutorials.
* Implement Conv2D node, test against pylearn2's.
* Write examples/mnist_conv.py
* Write examples/cifar10.py
* Write data/norb.py
* Replicate classification success on big NORB
* Replicate classification + orientation success.
* Write classification demo
